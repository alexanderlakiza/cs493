{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHX9p5jfTySS"
   },
   "source": [
    "## Задание 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EnHNZtbXlH0"
   },
   "source": [
    "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJox-LoonoPx"
   },
   "source": [
    "Применим полученные навыки и решим задачу анализа тональности отзывов. \n",
    "\n",
    "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
    "\n",
    "Обязательные шаги предобработки:\n",
    "1. токенизация\n",
    "2. приведение к нижнему регистру\n",
    "3. удаление стоп-слов\n",
    "4. лемматизация\n",
    "5. векторизация (с настройкой гиперпараметров)\n",
    "6. построение модели\n",
    "7. оценка качества модели\n",
    "\n",
    "Обязательно использование векторайзеров:\n",
    "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
    "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
    "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
    "\n",
    "В качестве классификатора нужно использовать наивный байесовский классификатор. \n",
    "\n",
    "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/women-clothing-accessories.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  качество плохое пошив ужасный (горловина напер...  negative\n",
       "1  Товар отдали другому человеку, я не получила п...  negative\n",
       "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
       "3  товар не пришел, продавец продлил защиту без м...  negative\n",
       "4      Кофточка голая синтетика, носить не возможно.  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'negative': 0,\n",
    "                                       'neautral': 1,\n",
    "                                       'positive': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review'].to_list()\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "stopwords = stopwords.words(\"russian\")\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 14s, sys: 2.39 s, total: 28min 16s\n",
      "Wall time: 28min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "punct_marks = string.punctuation + \"—\" + \"«\" + \"»\" + \"`\" + \"``\" + \"...\" + \"“\" \\\n",
    "+ \"''\" + \"”\" + '’' + '…'\n",
    "auxiliary_pos = ['NPRO', 'PREP', 'CONJ', 'PRCL', 'INTJ']\n",
    "for i in range(len(X)):\n",
    "    X[i] = re.sub(r'@', '', X[i])  # удаление @\n",
    "    X[i] = re.sub('http://\\S+|https://\\S+', '', X[i])  # удаление ссылок\n",
    "    X[i] = re.sub('http[s]?://\\S+', '', X[i])\n",
    "    X[i] = word_tokenize(X[i])  # токенизация\n",
    "    X[i] = [morph.parse(word)[0].normal_form for word in X[i]]  # лемматизация\n",
    "    X[i] = [word.lower() for word in X[i] if word not in punct_marks]\n",
    "    # нижний регистр и знаки препинания\n",
    "    X[i] = [word for word in X[i] if morph.parse(word[0])[0].tag.POS not in auxiliary_pos]\n",
    "    # удаление слов служебных частей речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [' '.join(text) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 2), (2, 3), (2, 4), (2, 5),\n",
    "          (2, 6), (3, 3), (3, 4)]\n",
    "table_n_gram = {'vectorizer': [], 'param': [], 'precision': [], 'recall': [],\n",
    "              'accuracy': [], 'f_1': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 6)\n",
      "(1, 7)\n",
      "(1, 8)\n",
      "(2, 2)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "(2, 6)\n",
      "(3, 3)\n",
      "(3, 4)\n",
      "CPU times: user 2min 3s, sys: 2.15 s, total: 2min 5s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = MultinomialNB()\n",
    "for param in n_grams:\n",
    "    vectorizer = CountVectorizer(ngram_range=param)\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    \n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    y_pred = clf.predict(X_test_vectorized)\n",
    "    \n",
    "    table_n_gram['vectorizer'].append('n-grams')\n",
    "    table_n_gram['param'].append(param)\n",
    "    table_n_gram['precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    table_n_gram['recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    table_n_gram['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    table_n_gram['f_1'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>param</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.657154</td>\n",
       "      <td>0.655376</td>\n",
       "      <td>0.655741</td>\n",
       "      <td>0.656190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.678057</td>\n",
       "      <td>0.675126</td>\n",
       "      <td>0.675481</td>\n",
       "      <td>0.676394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.677934</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.676037</td>\n",
       "      <td>0.676554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.676975</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.675326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>0.674622</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>0.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.676925</td>\n",
       "      <td>0.674451</td>\n",
       "      <td>0.674630</td>\n",
       "      <td>0.674961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>0.676954</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.674955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 8)</td>\n",
       "      <td>0.676965</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.674946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.649206</td>\n",
       "      <td>0.645015</td>\n",
       "      <td>0.645074</td>\n",
       "      <td>0.645352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.646515</td>\n",
       "      <td>0.643110</td>\n",
       "      <td>0.643111</td>\n",
       "      <td>0.642494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>0.644466</td>\n",
       "      <td>0.641181</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.640216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.643996</td>\n",
       "      <td>0.640598</td>\n",
       "      <td>0.640556</td>\n",
       "      <td>0.639569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 6)</td>\n",
       "      <td>0.644032</td>\n",
       "      <td>0.640567</td>\n",
       "      <td>0.640519</td>\n",
       "      <td>0.639487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.573173</td>\n",
       "      <td>0.556837</td>\n",
       "      <td>0.556111</td>\n",
       "      <td>0.549933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.570002</td>\n",
       "      <td>0.554331</td>\n",
       "      <td>0.553593</td>\n",
       "      <td>0.546959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vectorizer   param  precision    recall  accuracy       f_1\n",
       "0     n-grams  (1, 1)   0.657154  0.655376  0.655741  0.656190\n",
       "1     n-grams  (1, 2)   0.678057  0.675126  0.675481  0.676394\n",
       "2     n-grams  (1, 3)   0.677934  0.675758  0.676037  0.676554\n",
       "3     n-grams  (1, 4)   0.676975  0.674749  0.674963  0.675326\n",
       "4     n-grams  (1, 5)   0.677055  0.674622  0.674815  0.675195\n",
       "5     n-grams  (1, 6)   0.676925  0.674451  0.674630  0.674961\n",
       "6     n-grams  (1, 7)   0.676954  0.674497  0.674667  0.674955\n",
       "7     n-grams  (1, 8)   0.676965  0.674500  0.674667  0.674946\n",
       "8     n-grams  (2, 2)   0.649206  0.645015  0.645074  0.645352\n",
       "9     n-grams  (2, 3)   0.646515  0.643110  0.643111  0.642494\n",
       "10    n-grams  (2, 4)   0.644466  0.641181  0.641148  0.640216\n",
       "11    n-grams  (2, 5)   0.643996  0.640598  0.640556  0.639569\n",
       "12    n-grams  (2, 6)   0.644032  0.640567  0.640519  0.639487\n",
       "13    n-grams  (3, 3)   0.573173  0.556837  0.556111  0.549933\n",
       "14    n-grams  (3, 4)   0.570002  0.554331  0.553593  0.546959"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams_table = pd.DataFrame.from_dict(table_n_gram)\n",
    "n_grams_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ranges = []\n",
    "for i in range(6, 11):\n",
    "    for j in range(2, 6):\n",
    "        n_ranges.append((j, i))\n",
    "table_n_char_gram = {'vectorizer': [], 'param': [], 'precision': [], 'recall': [], \n",
    "                     'accuracy': [], 'f_1': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_n_char_gram = {'vectorizer': [], 'param': [], 'precision': [], 'recall': [], \n",
    "                     'accuracy': [], 'f_1': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer': [],\n",
       " 'param': [],\n",
       " 'precision': [],\n",
       " 'recall': [],\n",
       " 'accuracy': [],\n",
       " 'f_1': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_n_char_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6)\n",
      "(3, 6)\n",
      "(4, 6)\n",
      "(5, 6)\n",
      "(2, 7)\n",
      "(3, 7)\n",
      "(4, 7)\n",
      "(5, 7)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(2, 9)\n",
      "(3, 9)\n",
      "(4, 9)\n",
      "(5, 9)\n",
      "(2, 10)\n",
      "(3, 10)\n",
      "(4, 10)\n",
      "(5, 10)\n",
      "CPU times: user 12min 32s, sys: 16.4 s, total: 12min 48s\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for param in n_ranges:\n",
    "    char_vectorizer = CountVectorizer(analyzer='char', ngram_range=param)\n",
    "    X_train_vectorized = char_vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = char_vectorizer.transform(X_test)\n",
    "    \n",
    "    clf2 = MultinomialNB()\n",
    "    clf2.fit(X_train_vectorized, y_train)\n",
    "    y_pred = clf2.predict(X_test_vectorized)\n",
    "    \n",
    "    table_n_char_gram['vectorizer'].append('n-char-grams')\n",
    "    table_n_char_gram['param'].append(param)\n",
    "    table_n_char_gram['precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    table_n_char_gram['recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    table_n_char_gram['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    table_n_char_gram['f_1'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "    \n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>param</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 6)</td>\n",
       "      <td>0.662442</td>\n",
       "      <td>0.656867</td>\n",
       "      <td>0.657296</td>\n",
       "      <td>0.658899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 6)</td>\n",
       "      <td>0.663702</td>\n",
       "      <td>0.658772</td>\n",
       "      <td>0.659185</td>\n",
       "      <td>0.660638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 6)</td>\n",
       "      <td>0.666155</td>\n",
       "      <td>0.661404</td>\n",
       "      <td>0.661815</td>\n",
       "      <td>0.663239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.667539</td>\n",
       "      <td>0.662827</td>\n",
       "      <td>0.663222</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 7)</td>\n",
       "      <td>0.667646</td>\n",
       "      <td>0.662388</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>0.664364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 7)</td>\n",
       "      <td>0.670155</td>\n",
       "      <td>0.665032</td>\n",
       "      <td>0.665444</td>\n",
       "      <td>0.666985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>0.667294</td>\n",
       "      <td>0.667704</td>\n",
       "      <td>0.669146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 7)</td>\n",
       "      <td>0.671149</td>\n",
       "      <td>0.666639</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>0.668466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 8)</td>\n",
       "      <td>0.672851</td>\n",
       "      <td>0.667550</td>\n",
       "      <td>0.667963</td>\n",
       "      <td>0.669575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.673897</td>\n",
       "      <td>0.668928</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.670866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 8)</td>\n",
       "      <td>0.673953</td>\n",
       "      <td>0.669298</td>\n",
       "      <td>0.669704</td>\n",
       "      <td>0.671157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 8)</td>\n",
       "      <td>0.673139</td>\n",
       "      <td>0.668756</td>\n",
       "      <td>0.669148</td>\n",
       "      <td>0.670558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.676452</td>\n",
       "      <td>0.671268</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.673295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 9)</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>0.671636</td>\n",
       "      <td>0.672037</td>\n",
       "      <td>0.673567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 9)</td>\n",
       "      <td>0.675888</td>\n",
       "      <td>0.671459</td>\n",
       "      <td>0.671852</td>\n",
       "      <td>0.673272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>0.675905</td>\n",
       "      <td>0.671807</td>\n",
       "      <td>0.672185</td>\n",
       "      <td>0.673518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 10)</td>\n",
       "      <td>0.677151</td>\n",
       "      <td>0.672534</td>\n",
       "      <td>0.672926</td>\n",
       "      <td>0.674408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 10)</td>\n",
       "      <td>0.677451</td>\n",
       "      <td>0.673165</td>\n",
       "      <td>0.673556</td>\n",
       "      <td>0.674934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 10)</td>\n",
       "      <td>0.677109</td>\n",
       "      <td>0.673215</td>\n",
       "      <td>0.673593</td>\n",
       "      <td>0.674856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>0.676384</td>\n",
       "      <td>0.672673</td>\n",
       "      <td>0.673037</td>\n",
       "      <td>0.674249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vectorizer    param  precision    recall  accuracy       f_1\n",
       "0   n-char-grams   (2, 6)   0.662442  0.656867  0.657296  0.658899\n",
       "1   n-char-grams   (3, 6)   0.663702  0.658772  0.659185  0.660638\n",
       "2   n-char-grams   (4, 6)   0.666155  0.661404  0.661815  0.663239\n",
       "3   n-char-grams   (5, 6)   0.667539  0.662827  0.663222  0.664700\n",
       "4   n-char-grams   (2, 7)   0.667646  0.662388  0.662815  0.664364\n",
       "5   n-char-grams   (3, 7)   0.670155  0.665032  0.665444  0.666985\n",
       "6   n-char-grams   (4, 7)   0.672012  0.667294  0.667704  0.669146\n",
       "7   n-char-grams   (5, 7)   0.671149  0.666639  0.667037  0.668466\n",
       "8   n-char-grams   (2, 8)   0.672851  0.667550  0.667963  0.669575\n",
       "9   n-char-grams   (3, 8)   0.673897  0.668928  0.669333  0.670866\n",
       "10  n-char-grams   (4, 8)   0.673953  0.669298  0.669704  0.671157\n",
       "11  n-char-grams   (5, 8)   0.673139  0.668756  0.669148  0.670558\n",
       "12  n-char-grams   (2, 9)   0.676452  0.671268  0.671667  0.673295\n",
       "13  n-char-grams   (3, 9)   0.676502  0.671636  0.672037  0.673567\n",
       "14  n-char-grams   (4, 9)   0.675888  0.671459  0.671852  0.673272\n",
       "15  n-char-grams   (5, 9)   0.675905  0.671807  0.672185  0.673518\n",
       "16  n-char-grams  (2, 10)   0.677151  0.672534  0.672926  0.674408\n",
       "17  n-char-grams  (3, 10)   0.677451  0.673165  0.673556  0.674934\n",
       "18  n-char-grams  (4, 10)   0.677109  0.673215  0.673593  0.674856\n",
       "19  n-char-grams  (5, 10)   0.676384  0.672673  0.673037  0.674249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_char_grams_table = pd.DataFrame.from_dict(table_n_char_gram)\n",
    "n_char_grams_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [(1, i) for i in range(2, 5)]\n",
    "max_dfs = [0.85, 0.95]\n",
    "min_dfs = [i for i in range(1, 3)]\n",
    "max_features = [50, 100, 200]\n",
    "\n",
    "tf_idf_table = {'vectorizer': [], 'param': [], 'precision': [], 'recall': [],\n",
    "              'accuracy': [], 'f_1': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(max_df=0.85, max_features=50, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.85, max_features=100, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.85, max_features=200, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.85, max_features=50, min_df=2, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.85, max_features=100, min_df=2, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.85, max_features=200, min_df=2, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.95, max_features=50, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.95, max_features=100, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.95, max_features=200, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.95, max_features=50, min_df=2, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.95, max_features=100, min_df=2, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.95, max_features=200, min_df=2, ngram_range=(1, 2))\n",
      "TfidfVectorizer(max_df=0.85, max_features=50, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.85, max_features=100, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.85, max_features=200, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.85, max_features=50, min_df=2, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.85, max_features=100, min_df=2, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.85, max_features=200, min_df=2, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.95, max_features=50, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.95, max_features=100, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.95, max_features=200, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.95, max_features=50, min_df=2, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.95, max_features=100, min_df=2, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.95, max_features=200, min_df=2, ngram_range=(1, 3))\n",
      "TfidfVectorizer(max_df=0.85, max_features=50, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.85, max_features=100, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.85, max_features=200, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.85, max_features=50, min_df=2, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.85, max_features=100, min_df=2, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.85, max_features=200, min_df=2, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.95, max_features=50, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.95, max_features=100, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.95, max_features=200, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.95, max_features=50, min_df=2, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.95, max_features=100, min_df=2, ngram_range=(1, 4))\n",
      "TfidfVectorizer(max_df=0.95, max_features=200, min_df=2, ngram_range=(1, 4))\n",
      "CPU times: user 3min 12s, sys: 2.22 s, total: 3min 15s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for rang in ranges:\n",
    "    for max_df in max_dfs:\n",
    "        for min_df in min_dfs:\n",
    "            for feat in max_features:\n",
    "                tfidf_vectorizer = TfidfVectorizer(ngram_range=rang,\n",
    "                                                   max_df=max_df, min_df=min_df, max_features=feat)\n",
    "                X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "                X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "                clf3 = MultinomialNB()\n",
    "                clf3.fit(X_train_vectorized, y_train)\n",
    "                y_pred = clf3.predict(X_test_vectorized)\n",
    "                print(tfidf_vectorizer)\n",
    "            \n",
    "                tf_idf_table['vectorizer'].append('tf-idf')\n",
    "                tf_idf_table['param'].append(f\"n:{rang}, min and max:({min_df},{max_df}), max_feats:{feat}\")\n",
    "                tf_idf_table['precision'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "                tf_idf_table['recall'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "                tf_idf_table['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "                tf_idf_table['f_1'].append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>param</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.85), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.85), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.85), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.85), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.85), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.85), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.85), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.85), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vectorizer                                          param  precision  \\\n",
       "0      tf-idf   n:(1, 2), min and max:(1,0.85), max_feats:50   0.564111   \n",
       "1      tf-idf  n:(1, 2), min and max:(1,0.85), max_feats:100   0.593623   \n",
       "2      tf-idf  n:(1, 2), min and max:(1,0.85), max_feats:200   0.625085   \n",
       "3      tf-idf   n:(1, 2), min and max:(2,0.85), max_feats:50   0.564111   \n",
       "4      tf-idf  n:(1, 2), min and max:(2,0.85), max_feats:100   0.593623   \n",
       "5      tf-idf  n:(1, 2), min and max:(2,0.85), max_feats:200   0.625085   \n",
       "6      tf-idf   n:(1, 2), min and max:(1,0.95), max_feats:50   0.564111   \n",
       "7      tf-idf  n:(1, 2), min and max:(1,0.95), max_feats:100   0.593623   \n",
       "8      tf-idf  n:(1, 2), min and max:(1,0.95), max_feats:200   0.625085   \n",
       "9      tf-idf   n:(1, 2), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "10     tf-idf  n:(1, 2), min and max:(2,0.95), max_feats:100   0.593623   \n",
       "11     tf-idf  n:(1, 2), min and max:(2,0.95), max_feats:200   0.625085   \n",
       "12     tf-idf   n:(1, 3), min and max:(1,0.85), max_feats:50   0.564111   \n",
       "13     tf-idf  n:(1, 3), min and max:(1,0.85), max_feats:100   0.592787   \n",
       "14     tf-idf  n:(1, 3), min and max:(1,0.85), max_feats:200   0.623951   \n",
       "15     tf-idf   n:(1, 3), min and max:(2,0.85), max_feats:50   0.564111   \n",
       "16     tf-idf  n:(1, 3), min and max:(2,0.85), max_feats:100   0.592787   \n",
       "17     tf-idf  n:(1, 3), min and max:(2,0.85), max_feats:200   0.623951   \n",
       "18     tf-idf   n:(1, 3), min and max:(1,0.95), max_feats:50   0.564111   \n",
       "19     tf-idf  n:(1, 3), min and max:(1,0.95), max_feats:100   0.592787   \n",
       "20     tf-idf  n:(1, 3), min and max:(1,0.95), max_feats:200   0.623951   \n",
       "21     tf-idf   n:(1, 3), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "22     tf-idf  n:(1, 3), min and max:(2,0.95), max_feats:100   0.592787   \n",
       "23     tf-idf  n:(1, 3), min and max:(2,0.95), max_feats:200   0.623951   \n",
       "24     tf-idf   n:(1, 4), min and max:(1,0.85), max_feats:50   0.564111   \n",
       "25     tf-idf  n:(1, 4), min and max:(1,0.85), max_feats:100   0.592787   \n",
       "26     tf-idf  n:(1, 4), min and max:(1,0.85), max_feats:200   0.623785   \n",
       "27     tf-idf   n:(1, 4), min and max:(2,0.85), max_feats:50   0.564111   \n",
       "28     tf-idf  n:(1, 4), min and max:(2,0.85), max_feats:100   0.592787   \n",
       "29     tf-idf  n:(1, 4), min and max:(2,0.85), max_feats:200   0.623785   \n",
       "30     tf-idf   n:(1, 4), min and max:(1,0.95), max_feats:50   0.564111   \n",
       "31     tf-idf  n:(1, 4), min and max:(1,0.95), max_feats:100   0.592787   \n",
       "32     tf-idf  n:(1, 4), min and max:(1,0.95), max_feats:200   0.623785   \n",
       "33     tf-idf   n:(1, 4), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "34     tf-idf  n:(1, 4), min and max:(2,0.95), max_feats:100   0.592787   \n",
       "35     tf-idf  n:(1, 4), min and max:(2,0.95), max_feats:200   0.623785   \n",
       "\n",
       "      recall  accuracy       f_1  \n",
       "0   0.562996  0.563037  0.563159  \n",
       "1   0.593635  0.593889  0.593595  \n",
       "2   0.623677  0.624037  0.624305  \n",
       "3   0.562996  0.563037  0.563159  \n",
       "4   0.593635  0.593889  0.593595  \n",
       "5   0.623677  0.624037  0.624305  \n",
       "6   0.562996  0.563037  0.563159  \n",
       "7   0.593635  0.593889  0.593595  \n",
       "8   0.623677  0.624037  0.624305  \n",
       "9   0.562996  0.563037  0.563159  \n",
       "10  0.593635  0.593889  0.593595  \n",
       "11  0.623677  0.624037  0.624305  \n",
       "12  0.562996  0.563037  0.563159  \n",
       "13  0.592732  0.593000  0.592744  \n",
       "14  0.622545  0.622963  0.623095  \n",
       "15  0.562996  0.563037  0.563159  \n",
       "16  0.592732  0.593000  0.592744  \n",
       "17  0.622545  0.622963  0.623095  \n",
       "18  0.562996  0.563037  0.563159  \n",
       "19  0.592732  0.593000  0.592744  \n",
       "20  0.622545  0.622963  0.623095  \n",
       "21  0.562996  0.563037  0.563159  \n",
       "22  0.592732  0.593000  0.592744  \n",
       "23  0.622545  0.622963  0.623095  \n",
       "24  0.562996  0.563037  0.563159  \n",
       "25  0.592732  0.593000  0.592744  \n",
       "26  0.622435  0.622852  0.622964  \n",
       "27  0.562996  0.563037  0.563159  \n",
       "28  0.592732  0.593000  0.592744  \n",
       "29  0.622435  0.622852  0.622964  \n",
       "30  0.562996  0.563037  0.563159  \n",
       "31  0.592732  0.593000  0.592744  \n",
       "32  0.622435  0.622852  0.622964  \n",
       "33  0.562996  0.563037  0.563159  \n",
       "34  0.592732  0.593000  0.592744  \n",
       "35  0.622435  0.622852  0.622964  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_table = pd.DataFrame.from_dict(tf_idf_table)\n",
    "tf_idf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([n_grams_table, n_char_grams_table, tf_idf_table], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>param</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.657154</td>\n",
       "      <td>0.655376</td>\n",
       "      <td>0.655741</td>\n",
       "      <td>0.656190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.678057</td>\n",
       "      <td>0.675126</td>\n",
       "      <td>0.675481</td>\n",
       "      <td>0.676394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.677934</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.676037</td>\n",
       "      <td>0.676554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.676975</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.675326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>0.674622</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>0.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>0.676925</td>\n",
       "      <td>0.674451</td>\n",
       "      <td>0.674630</td>\n",
       "      <td>0.674961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>0.676954</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.674955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 8)</td>\n",
       "      <td>0.676965</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.674946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.649206</td>\n",
       "      <td>0.645015</td>\n",
       "      <td>0.645074</td>\n",
       "      <td>0.645352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.646515</td>\n",
       "      <td>0.643110</td>\n",
       "      <td>0.643111</td>\n",
       "      <td>0.642494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>0.644466</td>\n",
       "      <td>0.641181</td>\n",
       "      <td>0.641148</td>\n",
       "      <td>0.640216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>0.643996</td>\n",
       "      <td>0.640598</td>\n",
       "      <td>0.640556</td>\n",
       "      <td>0.639569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(2, 6)</td>\n",
       "      <td>0.644032</td>\n",
       "      <td>0.640567</td>\n",
       "      <td>0.640519</td>\n",
       "      <td>0.639487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.573173</td>\n",
       "      <td>0.556837</td>\n",
       "      <td>0.556111</td>\n",
       "      <td>0.549933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>0.570002</td>\n",
       "      <td>0.554331</td>\n",
       "      <td>0.553593</td>\n",
       "      <td>0.546959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 6)</td>\n",
       "      <td>0.662442</td>\n",
       "      <td>0.656867</td>\n",
       "      <td>0.657296</td>\n",
       "      <td>0.658899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 6)</td>\n",
       "      <td>0.663702</td>\n",
       "      <td>0.658772</td>\n",
       "      <td>0.659185</td>\n",
       "      <td>0.660638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 6)</td>\n",
       "      <td>0.666155</td>\n",
       "      <td>0.661404</td>\n",
       "      <td>0.661815</td>\n",
       "      <td>0.663239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 6)</td>\n",
       "      <td>0.667539</td>\n",
       "      <td>0.662827</td>\n",
       "      <td>0.663222</td>\n",
       "      <td>0.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 7)</td>\n",
       "      <td>0.667646</td>\n",
       "      <td>0.662388</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>0.664364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 7)</td>\n",
       "      <td>0.670155</td>\n",
       "      <td>0.665032</td>\n",
       "      <td>0.665444</td>\n",
       "      <td>0.666985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 7)</td>\n",
       "      <td>0.672012</td>\n",
       "      <td>0.667294</td>\n",
       "      <td>0.667704</td>\n",
       "      <td>0.669146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 7)</td>\n",
       "      <td>0.671149</td>\n",
       "      <td>0.666639</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>0.668466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 8)</td>\n",
       "      <td>0.672851</td>\n",
       "      <td>0.667550</td>\n",
       "      <td>0.667963</td>\n",
       "      <td>0.669575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 8)</td>\n",
       "      <td>0.673897</td>\n",
       "      <td>0.668928</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.670866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 8)</td>\n",
       "      <td>0.673953</td>\n",
       "      <td>0.669298</td>\n",
       "      <td>0.669704</td>\n",
       "      <td>0.671157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 8)</td>\n",
       "      <td>0.673139</td>\n",
       "      <td>0.668756</td>\n",
       "      <td>0.669148</td>\n",
       "      <td>0.670558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 9)</td>\n",
       "      <td>0.676452</td>\n",
       "      <td>0.671268</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.673295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 9)</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>0.671636</td>\n",
       "      <td>0.672037</td>\n",
       "      <td>0.673567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 9)</td>\n",
       "      <td>0.675888</td>\n",
       "      <td>0.671459</td>\n",
       "      <td>0.671852</td>\n",
       "      <td>0.673272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 9)</td>\n",
       "      <td>0.675905</td>\n",
       "      <td>0.671807</td>\n",
       "      <td>0.672185</td>\n",
       "      <td>0.673518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(2, 10)</td>\n",
       "      <td>0.677151</td>\n",
       "      <td>0.672534</td>\n",
       "      <td>0.672926</td>\n",
       "      <td>0.674408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(3, 10)</td>\n",
       "      <td>0.677451</td>\n",
       "      <td>0.673165</td>\n",
       "      <td>0.673556</td>\n",
       "      <td>0.674934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(4, 10)</td>\n",
       "      <td>0.677109</td>\n",
       "      <td>0.673215</td>\n",
       "      <td>0.673593</td>\n",
       "      <td>0.674856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>n-char-grams</td>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>0.676384</td>\n",
       "      <td>0.672673</td>\n",
       "      <td>0.673037</td>\n",
       "      <td>0.674249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.85), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.85), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.85), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.85), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.593623</td>\n",
       "      <td>0.593635</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>0.593595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 2), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.625085</td>\n",
       "      <td>0.623677</td>\n",
       "      <td>0.624037</td>\n",
       "      <td>0.624305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.85), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.85), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 3), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.623951</td>\n",
       "      <td>0.622545</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.85), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.85), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.85), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.85), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vectorizer                                          param  precision  \\\n",
       "0        n-grams                                         (1, 1)   0.657154   \n",
       "1        n-grams                                         (1, 2)   0.678057   \n",
       "2        n-grams                                         (1, 3)   0.677934   \n",
       "3        n-grams                                         (1, 4)   0.676975   \n",
       "4        n-grams                                         (1, 5)   0.677055   \n",
       "5        n-grams                                         (1, 6)   0.676925   \n",
       "6        n-grams                                         (1, 7)   0.676954   \n",
       "7        n-grams                                         (1, 8)   0.676965   \n",
       "8        n-grams                                         (2, 2)   0.649206   \n",
       "9        n-grams                                         (2, 3)   0.646515   \n",
       "10       n-grams                                         (2, 4)   0.644466   \n",
       "11       n-grams                                         (2, 5)   0.643996   \n",
       "12       n-grams                                         (2, 6)   0.644032   \n",
       "13       n-grams                                         (3, 3)   0.573173   \n",
       "14       n-grams                                         (3, 4)   0.570002   \n",
       "15  n-char-grams                                         (2, 6)   0.662442   \n",
       "16  n-char-grams                                         (3, 6)   0.663702   \n",
       "17  n-char-grams                                         (4, 6)   0.666155   \n",
       "18  n-char-grams                                         (5, 6)   0.667539   \n",
       "19  n-char-grams                                         (2, 7)   0.667646   \n",
       "20  n-char-grams                                         (3, 7)   0.670155   \n",
       "21  n-char-grams                                         (4, 7)   0.672012   \n",
       "22  n-char-grams                                         (5, 7)   0.671149   \n",
       "23  n-char-grams                                         (2, 8)   0.672851   \n",
       "24  n-char-grams                                         (3, 8)   0.673897   \n",
       "25  n-char-grams                                         (4, 8)   0.673953   \n",
       "26  n-char-grams                                         (5, 8)   0.673139   \n",
       "27  n-char-grams                                         (2, 9)   0.676452   \n",
       "28  n-char-grams                                         (3, 9)   0.676502   \n",
       "29  n-char-grams                                         (4, 9)   0.675888   \n",
       "30  n-char-grams                                         (5, 9)   0.675905   \n",
       "31  n-char-grams                                        (2, 10)   0.677151   \n",
       "32  n-char-grams                                        (3, 10)   0.677451   \n",
       "33  n-char-grams                                        (4, 10)   0.677109   \n",
       "34  n-char-grams                                        (5, 10)   0.676384   \n",
       "35        tf-idf   n:(1, 2), min and max:(1,0.85), max_feats:50   0.564111   \n",
       "36        tf-idf  n:(1, 2), min and max:(1,0.85), max_feats:100   0.593623   \n",
       "37        tf-idf  n:(1, 2), min and max:(1,0.85), max_feats:200   0.625085   \n",
       "38        tf-idf   n:(1, 2), min and max:(2,0.85), max_feats:50   0.564111   \n",
       "39        tf-idf  n:(1, 2), min and max:(2,0.85), max_feats:100   0.593623   \n",
       "40        tf-idf  n:(1, 2), min and max:(2,0.85), max_feats:200   0.625085   \n",
       "41        tf-idf   n:(1, 2), min and max:(1,0.95), max_feats:50   0.564111   \n",
       "42        tf-idf  n:(1, 2), min and max:(1,0.95), max_feats:100   0.593623   \n",
       "43        tf-idf  n:(1, 2), min and max:(1,0.95), max_feats:200   0.625085   \n",
       "44        tf-idf   n:(1, 2), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "45        tf-idf  n:(1, 2), min and max:(2,0.95), max_feats:100   0.593623   \n",
       "46        tf-idf  n:(1, 2), min and max:(2,0.95), max_feats:200   0.625085   \n",
       "47        tf-idf   n:(1, 3), min and max:(1,0.85), max_feats:50   0.564111   \n",
       "48        tf-idf  n:(1, 3), min and max:(1,0.85), max_feats:100   0.592787   \n",
       "49        tf-idf  n:(1, 3), min and max:(1,0.85), max_feats:200   0.623951   \n",
       "50        tf-idf   n:(1, 3), min and max:(2,0.85), max_feats:50   0.564111   \n",
       "51        tf-idf  n:(1, 3), min and max:(2,0.85), max_feats:100   0.592787   \n",
       "52        tf-idf  n:(1, 3), min and max:(2,0.85), max_feats:200   0.623951   \n",
       "53        tf-idf   n:(1, 3), min and max:(1,0.95), max_feats:50   0.564111   \n",
       "54        tf-idf  n:(1, 3), min and max:(1,0.95), max_feats:100   0.592787   \n",
       "55        tf-idf  n:(1, 3), min and max:(1,0.95), max_feats:200   0.623951   \n",
       "56        tf-idf   n:(1, 3), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "57        tf-idf  n:(1, 3), min and max:(2,0.95), max_feats:100   0.592787   \n",
       "58        tf-idf  n:(1, 3), min and max:(2,0.95), max_feats:200   0.623951   \n",
       "59        tf-idf   n:(1, 4), min and max:(1,0.85), max_feats:50   0.564111   \n",
       "60        tf-idf  n:(1, 4), min and max:(1,0.85), max_feats:100   0.592787   \n",
       "61        tf-idf  n:(1, 4), min and max:(1,0.85), max_feats:200   0.623785   \n",
       "62        tf-idf   n:(1, 4), min and max:(2,0.85), max_feats:50   0.564111   \n",
       "63        tf-idf  n:(1, 4), min and max:(2,0.85), max_feats:100   0.592787   \n",
       "64        tf-idf  n:(1, 4), min and max:(2,0.85), max_feats:200   0.623785   \n",
       "65        tf-idf   n:(1, 4), min and max:(1,0.95), max_feats:50   0.564111   \n",
       "66        tf-idf  n:(1, 4), min and max:(1,0.95), max_feats:100   0.592787   \n",
       "67        tf-idf  n:(1, 4), min and max:(1,0.95), max_feats:200   0.623785   \n",
       "68        tf-idf   n:(1, 4), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "69        tf-idf  n:(1, 4), min and max:(2,0.95), max_feats:100   0.592787   \n",
       "70        tf-idf  n:(1, 4), min and max:(2,0.95), max_feats:200   0.623785   \n",
       "\n",
       "      recall  accuracy       f_1  \n",
       "0   0.655376  0.655741  0.656190  \n",
       "1   0.675126  0.675481  0.676394  \n",
       "2   0.675758  0.676037  0.676554  \n",
       "3   0.674749  0.674963  0.675326  \n",
       "4   0.674622  0.674815  0.675195  \n",
       "5   0.674451  0.674630  0.674961  \n",
       "6   0.674497  0.674667  0.674955  \n",
       "7   0.674500  0.674667  0.674946  \n",
       "8   0.645015  0.645074  0.645352  \n",
       "9   0.643110  0.643111  0.642494  \n",
       "10  0.641181  0.641148  0.640216  \n",
       "11  0.640598  0.640556  0.639569  \n",
       "12  0.640567  0.640519  0.639487  \n",
       "13  0.556837  0.556111  0.549933  \n",
       "14  0.554331  0.553593  0.546959  \n",
       "15  0.656867  0.657296  0.658899  \n",
       "16  0.658772  0.659185  0.660638  \n",
       "17  0.661404  0.661815  0.663239  \n",
       "18  0.662827  0.663222  0.664700  \n",
       "19  0.662388  0.662815  0.664364  \n",
       "20  0.665032  0.665444  0.666985  \n",
       "21  0.667294  0.667704  0.669146  \n",
       "22  0.666639  0.667037  0.668466  \n",
       "23  0.667550  0.667963  0.669575  \n",
       "24  0.668928  0.669333  0.670866  \n",
       "25  0.669298  0.669704  0.671157  \n",
       "26  0.668756  0.669148  0.670558  \n",
       "27  0.671268  0.671667  0.673295  \n",
       "28  0.671636  0.672037  0.673567  \n",
       "29  0.671459  0.671852  0.673272  \n",
       "30  0.671807  0.672185  0.673518  \n",
       "31  0.672534  0.672926  0.674408  \n",
       "32  0.673165  0.673556  0.674934  \n",
       "33  0.673215  0.673593  0.674856  \n",
       "34  0.672673  0.673037  0.674249  \n",
       "35  0.562996  0.563037  0.563159  \n",
       "36  0.593635  0.593889  0.593595  \n",
       "37  0.623677  0.624037  0.624305  \n",
       "38  0.562996  0.563037  0.563159  \n",
       "39  0.593635  0.593889  0.593595  \n",
       "40  0.623677  0.624037  0.624305  \n",
       "41  0.562996  0.563037  0.563159  \n",
       "42  0.593635  0.593889  0.593595  \n",
       "43  0.623677  0.624037  0.624305  \n",
       "44  0.562996  0.563037  0.563159  \n",
       "45  0.593635  0.593889  0.593595  \n",
       "46  0.623677  0.624037  0.624305  \n",
       "47  0.562996  0.563037  0.563159  \n",
       "48  0.592732  0.593000  0.592744  \n",
       "49  0.622545  0.622963  0.623095  \n",
       "50  0.562996  0.563037  0.563159  \n",
       "51  0.592732  0.593000  0.592744  \n",
       "52  0.622545  0.622963  0.623095  \n",
       "53  0.562996  0.563037  0.563159  \n",
       "54  0.592732  0.593000  0.592744  \n",
       "55  0.622545  0.622963  0.623095  \n",
       "56  0.562996  0.563037  0.563159  \n",
       "57  0.592732  0.593000  0.592744  \n",
       "58  0.622545  0.622963  0.623095  \n",
       "59  0.562996  0.563037  0.563159  \n",
       "60  0.592732  0.593000  0.592744  \n",
       "61  0.622435  0.622852  0.622964  \n",
       "62  0.562996  0.563037  0.563159  \n",
       "63  0.592732  0.593000  0.592744  \n",
       "64  0.622435  0.622852  0.622964  \n",
       "65  0.562996  0.563037  0.563159  \n",
       "66  0.592732  0.593000  0.592744  \n",
       "67  0.622435  0.622852  0.622964  \n",
       "68  0.562996  0.563037  0.563159  \n",
       "69  0.592732  0.593000  0.592744  \n",
       "70  0.622435  0.622852  0.622964  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>param</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.657154</td>\n",
       "      <td>0.655376</td>\n",
       "      <td>0.655741</td>\n",
       "      <td>0.656190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.678057</td>\n",
       "      <td>0.675126</td>\n",
       "      <td>0.675481</td>\n",
       "      <td>0.676394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.677934</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.676037</td>\n",
       "      <td>0.676554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.676975</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.675326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>0.674622</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>0.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(1,0.95), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:50</td>\n",
       "      <td>0.564111</td>\n",
       "      <td>0.562996</td>\n",
       "      <td>0.563037</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:100</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.592732</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.592744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tf-idf</td>\n",
       "      <td>n:(1, 4), min and max:(2,0.95), max_feats:200</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>0.622435</td>\n",
       "      <td>0.622852</td>\n",
       "      <td>0.622964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vectorizer                                          param  precision  \\\n",
       "0     n-grams                                         (1, 1)   0.657154   \n",
       "1     n-grams                                         (1, 2)   0.678057   \n",
       "2     n-grams                                         (1, 3)   0.677934   \n",
       "3     n-grams                                         (1, 4)   0.676975   \n",
       "4     n-grams                                         (1, 5)   0.677055   \n",
       "..        ...                                            ...        ...   \n",
       "66     tf-idf  n:(1, 4), min and max:(1,0.95), max_feats:100   0.592787   \n",
       "67     tf-idf  n:(1, 4), min and max:(1,0.95), max_feats:200   0.623785   \n",
       "68     tf-idf   n:(1, 4), min and max:(2,0.95), max_feats:50   0.564111   \n",
       "69     tf-idf  n:(1, 4), min and max:(2,0.95), max_feats:100   0.592787   \n",
       "70     tf-idf  n:(1, 4), min and max:(2,0.95), max_feats:200   0.623785   \n",
       "\n",
       "      recall  accuracy       f_1  \n",
       "0   0.655376  0.655741  0.656190  \n",
       "1   0.675126  0.675481  0.676394  \n",
       "2   0.675758  0.676037  0.676554  \n",
       "3   0.674749  0.674963  0.675326  \n",
       "4   0.674622  0.674815  0.675195  \n",
       "..       ...       ...       ...  \n",
       "66  0.592732  0.593000  0.592744  \n",
       "67  0.622435  0.622852  0.622964  \n",
       "68  0.562996  0.563037  0.563159  \n",
       "69  0.592732  0.593000  0.592744  \n",
       "70  0.622435  0.622852  0.622964  \n",
       "\n",
       "[71 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>param</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.677934</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.676037</td>\n",
       "      <td>0.676554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.678057</td>\n",
       "      <td>0.675126</td>\n",
       "      <td>0.675481</td>\n",
       "      <td>0.676394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0.676975</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>0.674963</td>\n",
       "      <td>0.675326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>0.674622</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>0.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n-grams</td>\n",
       "      <td>(1, 7)</td>\n",
       "      <td>0.676954</td>\n",
       "      <td>0.674497</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.674955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vectorizer   param  precision    recall  accuracy       f_1\n",
       "2    n-grams  (1, 3)   0.677934  0.675758  0.676037  0.676554\n",
       "1    n-grams  (1, 2)   0.678057  0.675126  0.675481  0.676394\n",
       "3    n-grams  (1, 4)   0.676975  0.674749  0.674963  0.675326\n",
       "4    n-grams  (1, 5)   0.677055  0.674622  0.674815  0.675195\n",
       "6    n-grams  (1, 7)   0.676954  0.674497  0.674667  0.674955"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.sort_values(by='accuracy', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676037037037037"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['vectorizer']=='n-grams']['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735925925925926"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['vectorizer']=='n-char-grams']['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6240370370370371"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['vectorizer']=='tf-idf']['accuracy'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат дал мешок n-грамм с наименьшими значениями n_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 462.625x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=final, x='accuracy', hue='vectorizer', kind='kde', fill=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QYTwyMtWhAZ"
   },
   "source": [
    "## Задание 5.2 Регулярные выражения\n",
    "\n",
    "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n",
    "\n",
    "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся.\n",
    "\n",
    "Для работы с регулярными выражениями есть библиотека **re**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "VaUW5S4gWhAb"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6aYh7Osl8xr"
   },
   "source": [
    "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
    "* **?а** - ноль или один символ **а**\n",
    "* **+а** - один или более символов **а**\n",
    "* **\\*а** - ноль или более символов **а** (не путать с +)\n",
    "* **.** - любое количество любого символа\n",
    "\n",
    "Пример:\n",
    "Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7zOFFA3l_KQ"
   },
   "source": [
    "Рассмотрим подробно несколько наиболее полезных функций:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbJrUpARWhAd"
   },
   "source": [
    "### findall\n",
    "возвращает список всех найденных непересекающихся совпадений.\n",
    "\n",
    "Регулярное выражение **ab+c.**: \n",
    "* **a** - просто символ **a**\n",
    "* **b+** - один или более символов **b**\n",
    "* **c** - просто символ **c**\n",
    "* **.** - любой символ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2athHzKuWhAd",
    "outputId": "ff2d7b25-31bb-4877-bd50-95442e6a8158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9FpIw5RWhAf"
   },
   "source": [
    "Вопрос на внимательность: почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5ttzoxEWhAg"
   },
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7ZR2AEq3WhAg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['На', 'ку', 'гр', 'бо', 'пр', 'че', 'ра']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.findall(r'\\b\\w\\w' ,\"Национальные и культурные границы более прозрачны, чем раньше.\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI18l-l9WhAk"
   },
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVKdRoc1WhAl",
    "outputId": "78b5d289-8e8c-4621-fe3c-34aa130c727c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10u5efuSWhAm"
   },
   "source": [
    "можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9U9EQZMwWhAn",
    "outputId": "45699604-9950-4185-cd4f-0e3ad6655629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "dVgPSjEOWhAp"
   },
   "outputs": [],
   "source": [
    "text = \"Наш мир живет в ситуации глобализации. Национальные и культурные границы более прозрачны, чем раньше. Люди путешествуют по всему миру с разными целями: чтобы отдыхать, работать и учиться. Иногда чьи-то родственники или друзья живут за границей, и поездки туда становятся регулярными. Конечно, каждому нужен удобный и доступный способ путешествовать на дальние расстояния. Некоторые люди предпочитают традиционные поезда, но не все железные дороги проходят через государственные границы. Кроме того, путешествие на поезде обычно занимает много времени. Что касается путешествий по морю, они тоже могут быть невозможными (например, между странами Центральной Европы) или вызывать плохое самочувствие. Поэтому наиболее популярный способ ездить за границу – путешествие на самолете.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Наш мир живет в ситуации глобализации. Национальные и культурные границы более прозрачны, чем раньше. Люди путешествуют по всему миру с разными целями: чтобы отдыхать, работать и учиться. Иногда чьи-то родственники или друзья живут за границей, и поездки туда становятся регулярными. Конечно, каждому нужен удобный и доступный способ путешествовать на дальние расстояния. Некоторые люди предпочитают традиционные поезда, но не все железные дороги проходят через государственные границы. Кроме того, путешествие на поезде обычно занимает много времени. Что касается путешествий по морю, они тоже могут быть невозможными (например, между странами Центральной Европы) или вызывать плохое самочувствие. Поэтому наиболее популярный способ ездить за границу – путешествие на самолете.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EMcMyflWhAp"
   },
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Наш мир живет в ситуации глобализации',\n",
       " ' Национальные и культурные границы более прозрачны, чем раньше',\n",
       " ' Люди путешествуют по всему миру с разными целями: чтобы отдыхать, работать и учиться. Иногда чьи-то родственники или друзья живут за границей, и поездки туда становятся регулярными. Конечно, каждому нужен удобный и доступный способ путешествовать на дальние расстояния. Некоторые люди предпочитают традиционные поезда, но не все железные дороги проходят через государственные границы. Кроме того, путешествие на поезде обычно занимает много времени. Что касается путешествий по морю, они тоже могут быть невозможными (например, между странами Центральной Европы) или вызывать плохое самочувствие. Поэтому наиболее популярный способ ездить за границу – путешествие на самолете.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.split(r'[.]', text, maxsplit=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wrEGqBSWhAr"
   },
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az3KxKWwWhAr",
    "outputId": "93f260be-ce79-405c-b21a-5ca8345ff4b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "s_Sdu7xlWhAu"
   },
   "outputs": [],
   "source": [
    "text = \"Наибольшее количество побед в сезоне (38 матчей): 29, «Челси» (2004/05, 2005/06)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD0n7_HPWhAt"
   },
   "source": [
    "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Наибольшее количество побед в сезоне (DIGDIG матчей): DIGDIG, «Челси» (DIGDIGDIGDIG/DIGDIG, DIGDIGDIGDIG/DIGDIG)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.sub(r'\\d', \"DIG\", text)  # если надо заменить все цифры\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Наибольшее количество побед в сезоне (DIG матчей): DIG, «Челси» (DIG/DIG, DIG/DIG)'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.sub(r'\\d+', \"DIG\", text)  # если надо заменить все числа\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8__oi1PWhAv"
   },
   "source": [
    "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Документация библиотеки re доступна по ссылке https://docs.python.org/3/library/re.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "KwNS9zt4WhAv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Документация библиотеки re доступна по ссылке '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.sub(r'http\\S+', '', text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gStgBJy2WhAx"
   },
   "source": [
    "### compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JstTupisWhAy",
    "outputId": "f60e13a6-9d93-46e5-f329-620f6072715f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXEXc3G0WhA2"
   },
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "nFvnIWbUWhA2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Национальные',\n",
       " 'культурные',\n",
       " 'границы',\n",
       " 'более',\n",
       " 'прозрачны',\n",
       " 'чем',\n",
       " 'раньше']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.compile(r'\\S{3,}\\b')\n",
    "result.findall(\"Национальные и культурные границы более прозрачны, чем раньше.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQDNZ3HQWhA3"
   },
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
    "\n",
    "```\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@gmail.com', '@test.in', '@analyticsvidhya.com', '@rest.biz']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.compile(\"@[\\w.]+\")\n",
    "result.findall(\"abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Zpq4QOU5Wg-H",
    "i_7DyyXRWg-K",
    "_JewKs4XU-so",
    "5yiLk1P_xYQ2",
    "VlWxW3e9Wg-m",
    "D39SSh0zWg-r",
    "rhVrgkSaWg_K",
    "XsRf9T_SWg_U",
    "ylKZG2MwWg_f",
    "9hedBdcYWhAH",
    "JrqW55jgWhAR",
    "5QYTwyMtWhAZ",
    "DbJrUpARWhAd",
    "MI18l-l9WhAk",
    "1wrEGqBSWhAr",
    "gStgBJy2WhAx"
   ],
   "name": "lab5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
