{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"Text_processing_webinar.ipynb","provenance":[{"file_id":"1SOx8vThNzVFZR_zaUlIZ56WxGNaVJ1hk","timestamp":1604754473954},{"file_id":"1XUT-Qa-VLIAMmHbt6pe3AdzDLSyaFoWv","timestamp":1604677054518},{"file_id":"1UpsFM_rY1G1r2EBkqj-A-3wpk1l_Ambe","timestamp":1596006394187},{"file_id":"1TtILmuSoWXOYmbTIAQmGaScvuHGWvpsI","timestamp":1595563808854},{"file_id":"1EdBdyqxLu-WiLmriWNwYl5Ct33JYcEG2","timestamp":1582113683695},{"file_id":"10_Aehfbxgr3fxXPgI1gM5BTU8yOy-Z4U","timestamp":1579514615233}],"collapsed_sections":["Zpq4QOU5Wg-H","i_7DyyXRWg-K","_JewKs4XU-so","5yiLk1P_xYQ2","VlWxW3e9Wg-m","D39SSh0zWg-r","rhVrgkSaWg_K","XsRf9T_SWg_U","ylKZG2MwWg_f","9hedBdcYWhAH","JrqW55jgWhAR","5QYTwyMtWhAZ","DbJrUpARWhAd","MI18l-l9WhAk","1wrEGqBSWhAr","gStgBJy2WhAx"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kz1hqb2oWg96"},"source":["# Инструменты для работы с текстом"]},{"cell_type":"markdown","metadata":{"id":"iXhKw6r2Wg97"},"source":["Анализ текстовых данных - это отдельное направление, здесь будет совсем небольшое введение.\n","С текстовыми данными можно решать как задачи обучения с учителем (классификация текстов), так и задачу обучения без учителя (кластеризация).\n","\n","Предобработка текста\n","\n","Первый шаг любой аналитики – получение данных. Предположим, что данные представляются собой набор текстов. Все известные нам алгоритмы работают не в текстами, а с объектами, которые описываются вектором признаков (чаще всего численных, категориальные мы умеем преобразовывать). Что делать, если наши объекты - это текст? \n","\n","Следующая после получения данных задача: предобработка. Основная цель предобработки: преобразовать текстовые данные в удобный для построения модели вид.\n","\n","Базовые шаги предобработки:\n","1. токенизация\n","2. приведение к нижнему регистру\n","3. удаление стоп-слов\n","4. удаление пунктуации\n","5. фильтрация по частоте/длине/соответствию регулярному выражению\n","6. лемматизация или стемминг\n","7. векторизация (эмбеддинг)\n","\n","Чаще всего применяются все эти шаги, но в разных задачах какие-то могут опускаться, поскольку приводят к потере информации"]},{"cell_type":"code","metadata":{"id":"IX-AeH8RWg9-"},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import * \n","from sklearn.model_selection import train_test_split "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zpq4QOU5Wg-H"},"source":["* Сейчас мы попробуем получить преобразование предложений в численный вектор, с которым может работать стандартный алгоритм машинного обучения. \n","* Для этого нам понадобится познакомиться с понятием n-gram - самых мелких элементов предложения, с которыми можно работать. \n","* Подсчитав количество этих n-грам в предложениях, мы получим искомые численные представления."]},{"cell_type":"markdown","metadata":{"id":"i_7DyyXRWg-K"},"source":["## n-граммы\n","\n","Самые мелкие структуры языка, с которыми мы работаем, называются **n-граммами**.\n","У n-граммы есть параметр n - количество слов, которые попадают в такое представление текста.\n","* Если n = 1 - то мы смотрим на то, сколько раз каждое слово встретилось в тексте. Получаем _униграммы_\n","* Если n = 2 - то мы смотрим на то, сколько раз каждая пара подряд идущих слов, встретилась в тексте. Получаем _биграммы_"]},{"cell_type":"markdown","metadata":{"id":"quiUoyqNb3WA"},"source":["Функция для работы с n-граммами реализована в библиотке **nltk** (Natural Language ToolKit), импортируем эту функцию: "]},{"cell_type":"code","metadata":{"id":"hcrWxBzzWg-K"},"source":["from nltk import ngrams"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ib-zYTvfQq5"},"source":["Прежде чем получать n-граммы, нужно разделить предложение на отдельные слова.  Для этого используем метод ```split()```."]},{"cell_type":"code","metadata":{"id":"wJ9aYx2UPK44"},"source":["sentence = 'Кто же победит на выборах в США: Трамп или Байден?'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2Ql8Em4Wg-N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733159087,"user_tz":-180,"elapsed":3322,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"fcd6f3a8-d134-47e9-dec2-2c22514360a9"},"source":["sentence_split = sentence.split()\n","sentence_split"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США:',\n"," 'Трамп',\n"," 'или',\n"," 'Байден?']"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"GVIvz7OLN8yV"},"source":["Кажется, что нам тут мешают знаки препинания. Дайвайте от них избавимся. "]},{"cell_type":"code","metadata":{"id":"3i3IvCTPOIfB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1604735224477,"user_tz":-180,"elapsed":2240,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"6078a7bd-be51-40f0-8afa-c0feb32af596"},"source":["import string\n","string.punctuation"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"]},"metadata":{"tags":[]},"execution_count":188}]},{"cell_type":"code","metadata":{"id":"NTiPD_lfPERo"},"source":["for ch in string.punctuation:\n","  sentence = sentence.replace(ch,\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eY7anMcPxGB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1604733159093,"user_tz":-180,"elapsed":3200,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"d3d67f89-cade-4cea-8c06-c9c9b733b640"},"source":["sentence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Кто же победит на выборах в США Трамп или Байден'"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"AWvXpEdDP4kI"},"source":["sentence_split = sentence.split()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uy1TrfAP-ui","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733159720,"user_tz":-180,"elapsed":3776,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"4367d045-1ef9-4cd8-c94e-c6dfcb9b1582"},"source":["sentence_split"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто', 'же', 'победит', 'на', 'выборах', 'в', 'США', 'Трамп', 'или', 'Байден']"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"d6V5P2Jcc4Oy"},"source":["Чтобы получить n-грамму для такой последовательности, используем функцию ```ngrams()```. \n","\n","На вход передается два параметра:\n","* лист с разделенным на отдельные слова предложением (у нас он хранится в переменной ```sent```);\n","* параметр n, определяющий, какой тип n-грамм мы хотим получить.\n","\n","\n","Чтобы полученный объект отобразить, делаем из него ```list```. "]},{"cell_type":"code","metadata":{"id":"F9oqpykUc5e9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733159722,"user_tz":-180,"elapsed":3740,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"59827db1-4aea-44d1-83aa-42822e822545"},"source":["list(ngrams(sentence_split, 1)) # униграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто',),\n"," ('же',),\n"," ('победит',),\n"," ('на',),\n"," ('выборах',),\n"," ('в',),\n"," ('США',),\n"," ('Трамп',),\n"," ('или',),\n"," ('Байден',)]"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"markdown","metadata":{"id":"GZKRhRlxfoj4"},"source":["Аналогично мы можем получить биграммы - для этого заменяем параметр **n** в функции **ngrams** с 1 на 2."]},{"cell_type":"code","metadata":{"id":"Bzl6t5dpWg-P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733159723,"user_tz":-180,"elapsed":3695,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"20a522db-a015-476c-c71b-7e1a8f0c46c2"},"source":["list(ngrams(sentence_split, 2)) # биграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто', 'же'),\n"," ('же', 'победит'),\n"," ('победит', 'на'),\n"," ('на', 'выборах'),\n"," ('выборах', 'в'),\n"," ('в', 'США'),\n"," ('США', 'Трамп'),\n"," ('Трамп', 'или'),\n"," ('или', 'Байден')]"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"nCkkFzWLWg-R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733159733,"user_tz":-180,"elapsed":3654,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"16d36f05-531d-40e2-b095-1d4e7cb7a7b7"},"source":["list(ngrams(sentence_split, 3)) # триграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто', 'же', 'победит'),\n"," ('же', 'победит', 'на'),\n"," ('победит', 'на', 'выборах'),\n"," ('на', 'выборах', 'в'),\n"," ('выборах', 'в', 'США'),\n"," ('в', 'США', 'Трамп'),\n"," ('США', 'Трамп', 'или'),\n"," ('Трамп', 'или', 'Байден')]"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"GygS6_fJWg-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733159735,"user_tz":-180,"elapsed":3616,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"645e55c5-5628-4f8a-c264-a4f55f1f2ddf"},"source":["list(ngrams(sentence_split, 5)) # ... пентаграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто', 'же', 'победит', 'на', 'выборах'),\n"," ('же', 'победит', 'на', 'выборах', 'в'),\n"," ('победит', 'на', 'выборах', 'в', 'США'),\n"," ('на', 'выборах', 'в', 'США', 'Трамп'),\n"," ('выборах', 'в', 'США', 'Трамп', 'или'),\n"," ('в', 'США', 'Трамп', 'или', 'Байден')]"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"markdown","metadata":{"id":"_JewKs4XU-so"},"source":["## Векторизаторы\n","\n","Векторизатор преобразует слово или набор слов в числовой вектор, понятный алгоритму машинного обучения, который привык работать с числовыми табличными данными.\n","\n","Ниже - пример преобразования слов в двумерных вектор, каждому слову соответствует точка на плоскости.\n","\n","<a href=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\n","\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\" \n","alt=\"IMAGE ALT TEXT HERE\" width=\"600\" border=\"0\" /></a>"]},{"cell_type":"markdown","metadata":{"id":"V5hiNv2eVAc-"},"source":["На начальном этапе нам будет достаточно тех инструментов, которые уже есть в библиотеке **sklearn**."]},{"cell_type":"code","metadata":{"id":"cPplZnxeVEBR"},"source":["from sklearn.tree import DecisionTreeClassifier # можно заменить на другой классификатор\n","from sklearn.naive_bayes import MultinomialNB # наивный байесовский классификатор\n","from sklearn.feature_extraction.text import CountVectorizer # модель \"мешка слов\", см. далее"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eBN16KYZWg-U"},"source":["Самый простой способ извлечь признаки из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n","\n","Объект `CountVectorizer` делает следующую вещь:\n","* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n","* заполняет каждый i-тый элемент количеством вхождений слова в данный документ\n","\n","<a href=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\n","\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1jHmkrGZTMawM46Yzxh243Ur1y5pYKzrl\" \n","alt=\"IMAGE ALT TEXT HERE\" width=\"600\" border=\"0\" /></a>"]},{"cell_type":"markdown","metadata":{"id":"oklbwY_vWg-X"},"source":["На рисунке пример векторизации для униграмм, но можно использовать любые n-граммы. Для этого у объекта ```CountVectorizer()``` есть параметр **ngram_range**, который отвечает за то, какие n-граммы мы используем в качестве признаов:<br/>\n","ngram_range=(1, 1) -- униграммы<br/>\n","ngram_range=(3, 3) -- триграммы<br/>\n","ngram_range=(1, 3) -- униграммы, биграммы и триграммы."]},{"cell_type":"markdown","metadata":{"id":"5KabRubaXhNb"},"source":["## Пример"]},{"cell_type":"markdown","metadata":{"id":"0EnHNZtbXlH0"},"source":["К сожалению, на русском языке всё ещё очень мало годных наборов данных. Набор данных нашёл тут: https://github.com/sismetanin/rureviews"]},{"cell_type":"code","metadata":{"id":"yX-0fRF3hzCy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733161979,"user_tz":-180,"elapsed":5800,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"05191d2f-784d-4b03-b2d1-38ea3a28b0bf"},"source":["!pip install PyDrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aYRCckjEh2--"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBBer1ozh5mL"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP_tPtQDiGCx"},"source":["downloaded = drive.CreateFile({'id':\"1j-DhO_XD5EqzOqVSR4Wz1kNzhLmpeTkZ\"}) \n","downloaded.GetContentFile('women-clothing-accessories.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6709r3nXwIu"},"source":["data = pd.read_csv('women-clothing-accessories.csv', sep='\\t', usecols=[0, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u894TFlsYq3o","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1604733164083,"user_tz":-180,"elapsed":7765,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"bd36b534-b9ed-4f2c-f1cb-fa4cd8f06752"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>качество плохое пошив ужасный (горловина напер...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Товар отдали другому человеку, я не получила п...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>товар не пришел, продавец продлил защиту без м...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Кофточка голая синтетика, носить не возможно.</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  качество плохое пошив ужасный (горловина напер...  negative\n","1  Товар отдали другому человеку, я не получила п...  negative\n","2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n","3  товар не пришел, продавец продлил защиту без м...  negative\n","4      Кофточка голая синтетика, носить не возможно.  negative"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"09aeAe4zvwCv","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1604733164085,"user_tz":-180,"elapsed":7694,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"a477e809-c4a0-40f6-852e-2392408051f6"},"source":["data.sample(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9700</th>\n","      <td>товар не пришел, деньги не вернули. продавец в...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>78254</th>\n","      <td>куртка пришла быстро, хорошего качества и без ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>69048</th>\n","      <td>Очень теплый кардиган, крупная вязка, ощущаетс...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>29445</th>\n","      <td>заказала размер М, по факту размер S. Рукава к...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27592</th>\n","      <td>товар не пришел, деньги вернули</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>25837</th>\n","      <td>Мятый, не держит, получила быстро</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>26702</th>\n","      <td>Качество пошива нормальное. Но!!! Пуховик выпо...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>74390</th>\n","      <td>Платье прикольное! Шло до Свердл.обл. ровно 1 ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>36988</th>\n","      <td>товар не пришел,вернули деньги.</td>\n","      <td>neautral</td>\n","    </tr>\n","    <tr>\n","      <th>15496</th>\n","      <td>Очень криво сшито. одна половина длиннее другой</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  review sentiment\n","9700   товар не пришел, деньги не вернули. продавец в...  negative\n","78254  куртка пришла быстро, хорошего качества и без ...  positive\n","69048  Очень теплый кардиган, крупная вязка, ощущаетс...  positive\n","29445  заказала размер М, по факту размер S. Рукава к...  negative\n","27592                    товар не пришел, деньги вернули  negative\n","25837                  Мятый, не держит, получила быстро  negative\n","26702  Качество пошива нормальное. Но!!! Пуховик выпо...  negative\n","74390  Платье прикольное! Шло до Свердл.обл. ровно 1 ...  positive\n","36988                    товар не пришел,вернули деньги.  neautral\n","15496    Очень криво сшито. одна половина длиннее другой  negative"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"DpWqBU3-ZL5F"},"source":["x_train, x_test, y_train, y_test = train_test_split(data.review, data.sentiment, train_size = 0.7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKB-qv_obPrD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733164114,"user_tz":-180,"elapsed":7673,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"f37c694a-2884-4019-d5dc-e621cb83eff8"},"source":["data.sentiment.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["neautral    30000\n","negative    30000\n","positive    30000\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"QtowE76LbIrG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733164125,"user_tz":-180,"elapsed":7649,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"d33143c9-7136-4272-8583-336d10c73867"},"source":["y_train.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["negative    21034\n","positive    21019\n","neautral    20946\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"muRPBnySwfih"},"source":["Инициализируем `CountVectorizer()`, указав в качестве признаков униграммы:"]},{"cell_type":"code","metadata":{"id":"SfavuPF9wZh_"},"source":["vectorizer = CountVectorizer(ngram_range=(1, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIxErQg4wm-H"},"source":["После инициализации _vectorizer_ можно обучить на наших данных. \n","\n","Для обучения используем обучающую выборку ```x_train```, но в отличие от классификатора мы используем метод ```fit_transform()```: сначала обучаем наш векторизатор, а потом сразу применяем его к нашему набору данных. Это похоже на то, как мы работали с one-hot-encoderом."]},{"cell_type":"code","metadata":{"id":"0iwq0gTww0Pw"},"source":["vectorized_x_train = vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Scw-UGKrwysI"},"source":["Так как результат не зависит от порядка слов в текстах, то говорят, что такая модель представления текстов в виде векторов получается из *гипотезы представления текста как мешка слов*"]},{"cell_type":"markdown","metadata":{"id":"IXZEX-AxxDp4"},"source":["В `vectorizer.vocabulary_` лежит словарь, отображение слов в их индексы:"]},{"cell_type":"code","metadata":{"id":"gRohdVRSxJIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733165659,"user_tz":-180,"elapsed":9098,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"f76ae09a-e09b-4707-d2b6-4dcca875577a"},"source":["list(vectorizer.vocabulary_.items())[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('пришёл', 31551),\n"," ('мал', 18011),\n"," ('материал', 18269),\n"," ('ожидался', 23477),\n"," ('другой', 11224),\n"," ('немного', 20996),\n"," ('прозрачный', 32010),\n"," ('товар', 39618),\n"," ('пришел', 31484),\n"," ('менее', 18455)]"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"id":"BQCbnAk4wS_K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733165662,"user_tz":-180,"elapsed":9060,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"28d1fc4e-dfa8-4993-cc0d-dfa180bdfb53"},"source":["vectorized_x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999, 44490)"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"CKFQVUZ11K47","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733165664,"user_tz":-180,"elapsed":9030,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"3c8c5ba4-4d43-4027-b55c-1e649b4a8fe5"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999,)"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"markdown","metadata":{"id":"gXAcWenlxQfc"},"source":["Так как теперь у нас есть **численное представление** и набор входных признаков, то мы можем обучить нашу модель"]},{"cell_type":"code","metadata":{"id":"icUoj9EexWcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733208743,"user_tz":-180,"elapsed":52069,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"342668c0-8df8-4757-e9f5-33e886c32dea"},"source":["clf = DecisionTreeClassifier()\n","clf.fit(vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=None, splitter='best')"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"id":"Hf9V0s6jI1l2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733208748,"user_tz":-180,"elapsed":52041,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"ed1a6caf-3ec2-426f-f0bc-22e52ed24111"},"source":["clf2 = MultinomialNB()\n","clf2.fit(vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"markdown","metadata":{"id":"jM85715BxfIx"},"source":["С тестовыми данными нужно проделать то же самое, что и с данными для обучения: сделать из текстов вектора, которые можно передавать в классификатор для прогноза класса объекта. \n","\n","У нас уже есть обученный векторизатор ```vectorizer```, поэтому используем метод ```transform()``` (просто применить его), а не ```fit_transform``` (обучить и применить)."]},{"cell_type":"code","metadata":{"id":"zWX6X7UHxjkj"},"source":["vectorized_x_test = vectorizer.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SzvSUzEcxqMo"},"source":["Как раньше, для получения прогноза у обученного классификатора используем метод ```predict()```.\n","\n","С помощью функции ```classification_report()```, которая считает сразу несколько метрик качества классификации, посмотрим на то, насколько хорошо мы предсказываем положительную или отрицательную тональность твита ."]},{"cell_type":"code","metadata":{"id":"V7gssLYYxwkK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733210261,"user_tz":-180,"elapsed":53496,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"97e16657-8eec-431a-8077-2ccdb1f86e8c"},"source":["pred = clf.predict(vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.52      0.53      0.52      9054\n","    negative       0.63      0.63      0.63      8966\n","    positive       0.76      0.75      0.76      8981\n","\n","    accuracy                           0.64     27001\n","   macro avg       0.64      0.64      0.64     27001\n","weighted avg       0.64      0.64      0.64     27001\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PvtntoJ0JNoK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733210752,"user_tz":-180,"elapsed":53953,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"8c29b688-fa2c-4a01-9288-70d8f74bcfc3"},"source":["pred2 = clf2.predict(vectorized_x_test)\n","print(classification_report(y_test, pred2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.66      0.62      9054\n","    negative       0.72      0.62      0.67      8966\n","    positive       0.84      0.85      0.84      8981\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.72      0.71      0.71     27001\n","weighted avg       0.72      0.71      0.71     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"seQ_QrKmJWoF"},"source":["Итак, наивный байесовский классификатор легко побил дерево решений. Дальше работаем с ним."]},{"cell_type":"markdown","metadata":{"id":"c6qcO2BceNsv"},"source":["### Отступление: F-мера"]},{"cell_type":"markdown","metadata":{"id":"z_qn9NrqeW6w"},"source":["Прошлый раз мы разобрали метрики качества классификации, которые выводятся из матрицы ошибок (confision matrix). \n","\n","**Полнота** (Sensitivity, True Positive Rate, Recall, Hit Rate) отражает какой процент объектов положительного класса мы правильно классифицировали.\n","\n","**Точность** (Precision, Positive Predictive Value) отражает какой процент положительных объектов (т.е. тех, что мы считаем положительными) правильно классифицирован. (Не путать с Accuracy!)\n","\n","Легко построить алгоритм со 100%-й полнотой: он все объекты относит к классу 1, но при этом точность может быть очень низкой. Нетрудно построить алгоритм с близкой к 100% точностью: он относит к классу 1 только те объекты, в которых уверен, при этом полнота может быть низкая.\n","\n","**F1-мера** (F1 score) является средним гармоническим точности и полноты, максимизация этого функционала приводит к одновременной максимизации этих двух «ортогональных критериев»\n","\n","$$F_1 = \\frac{2}{\\mathrm{recall}^{-1} + \\mathrm{precision}^{-1}} = 2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}} = \\frac{\\mathrm{tp}}{\\mathrm{tp} + \\frac12 (\\mathrm{fp} + \\mathrm{fn}) } $$\n","\n","Также рассматривают весовое среднее гармоническое точности и полноты –  $F_\\beta$-меру:\n","\n","$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{(\\beta^2 \\cdot \\mathrm{precision}) + \\mathrm{recall}} = \\frac {(1 + \\beta^2) \\cdot \\mathrm{tp} }{(1 + \\beta^2) \\cdot \\mathrm{tp} + \\beta^2 \\cdot \\mathrm{fn} + \\mathrm{fp}}\\,$$\n","\n","Изменение $\\beta$ позволяет делать один из критериев (точность или полноту) важнее при оптимизации."]},{"cell_type":"markdown","metadata":{"id":"5yiLk1P_xYQ2"},"source":["## Биграммы"]},{"cell_type":"markdown","metadata":{"id":"mjy5ZPmwWg-j"},"source":["Попробуем сделать то же самое, используя в качестве признаков униграммы и биграммы:"]},{"cell_type":"code","metadata":{"id":"JKeS-Vmv13SE"},"source":["# инициализируем векторайзер \n","bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmQHqUpRWg-k"},"source":["# обучаем его и сразу применяем к x_train\n","bigram_vectorized_x_train = bigram_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfG5x9i91_n4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733215634,"user_tz":-180,"elapsed":58770,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"1f981415-4908-4c61-ecfd-910de8443791"},"source":["# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(bigram_vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"id":"twUcp7eU2E-9"},"source":["# применяем обученный векторизатор к тестовым данным\n","bigram_vectorized_x_test = bigram_vectorizer.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPsfMX7i2H1j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217525,"user_tz":-180,"elapsed":60611,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"c5182abb-b6ff-4797-cea6-17a3f04ef663"},"source":["# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(bigram_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.61      0.67      0.64      9054\n","    negative       0.72      0.66      0.69      8966\n","    positive       0.87      0.86      0.87      8981\n","\n","    accuracy                           0.73     27001\n","   macro avg       0.74      0.73      0.73     27001\n","weighted avg       0.74      0.73      0.73     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MonLW7AyWg-m"},"source":["У меня получилось повысить точность на пару процентов по сравнению с униграммами"]},{"cell_type":"code","metadata":{"id":"cdwrMRN93D31","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217527,"user_tz":-180,"elapsed":60580,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"bb4213fe-2d8c-4a78-b6f4-7e0d68b859c2"},"source":["bigram_vectorized_x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999, 461507)"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"markdown","metadata":{"id":"ZHzVwaMF3LPY"},"source":["\"Признаков\" объектов стало на порядок больше."]},{"cell_type":"markdown","metadata":{"id":"D39SSh0zWg-r"},"source":["## Токенизация\n","\n","Токенизировать - значит, поделить текст на части: слова, ключевые слова, фразы, символы и т.д., иными словами **токены**.\n","\n","Самый наивный способ токенизировать текст - разделить с помощью функции `split()`. Но `split` упускает очень много всего, например, не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем, поэтому лучше использовать готовые токенизаторы."]},{"cell_type":"code","metadata":{"id":"hoSe08N2Wg-r"},"source":["import nltk # уже знакомая нам библиотека nltk\n","from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiDt3L8Y8god"},"source":["Чтобы использовать токенизатор ```word_tokenize```, нужно сначала скачать данные для nltk о пунктуации и стоп-словах."]},{"cell_type":"code","metadata":{"id":"gPH3yMcumsdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217531,"user_tz":-180,"elapsed":60532,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"c0e4735e-bcc4-4243-dfce-3e187b9aaeff"},"source":["nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"markdown","metadata":{"id":"3NfDb8D_9DqD"},"source":["Применим токенизацию:"]},{"cell_type":"code","metadata":{"id":"zrJDGpgYWg-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217532,"user_tz":-180,"elapsed":60497,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"7a9c15f5-2d4e-45fc-cf89-4a5f2b77f4c5"},"source":["sentence = 'Кто же победит на выборах в США: Трамп или Байден?'\n","word_tokenize(sentence)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США',\n"," ':',\n"," 'Трамп',\n"," 'или',\n"," 'Байден',\n"," '?']"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"vxy7KGZI9bhK"},"source":["Сравните с использованием ```split()```:"]},{"cell_type":"code","metadata":{"id":"p52dIuSI9W6o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217533,"user_tz":-180,"elapsed":60466,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"cdc9b436-53c9-4df3-b797-03170d50040a"},"source":["sentence.split()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США:',\n"," 'Трамп',\n"," 'или',\n"," 'Байден?']"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"_702Dg5OWg-5"},"source":["В nltk вообще есть довольно много токенизаторов:"]},{"cell_type":"code","metadata":{"id":"Ps8oPYoTWg-6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217535,"user_tz":-180,"elapsed":60436,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"4f27d387-2379-4a48-db64-814c774e6710"},"source":["from nltk import tokenize\n","dir(tokenize)[:16]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['BlanklineTokenizer',\n"," 'LineTokenizer',\n"," 'MWETokenizer',\n"," 'PunktSentenceTokenizer',\n"," 'RegexpTokenizer',\n"," 'ReppTokenizer',\n"," 'SExprTokenizer',\n"," 'SpaceTokenizer',\n"," 'StanfordSegmenter',\n"," 'TabTokenizer',\n"," 'TextTilingTokenizer',\n"," 'ToktokTokenizer',\n"," 'TreebankWordTokenizer',\n"," 'TweetTokenizer',\n"," 'WhitespaceTokenizer',\n"," 'WordPunctTokenizer']"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"lmnGCL5iWg-8"},"source":["Одни умеют выдавать индексы в строке для начала и конца каждого слова-токена:"]},{"cell_type":"code","metadata":{"id":"Jejj5X7QWg-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217536,"user_tz":-180,"elapsed":60412,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"5707296d-5720-4b2d-fa88-e983699d069c"},"source":["wh_tok = tokenize.WhitespaceTokenizer()\n","list(wh_tok.span_tokenize(sentence))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 3),\n"," (4, 6),\n"," (7, 14),\n"," (15, 17),\n"," (18, 25),\n"," (26, 27),\n"," (28, 32),\n"," (33, 38),\n"," (39, 42),\n"," (43, 50)]"]},"metadata":{"tags":[]},"execution_count":115}]},{"cell_type":"markdown","metadata":{"id":"a-wf6A1EWg--"},"source":["Некторые токенизаторы ведут себя специфично:"]},{"cell_type":"code","metadata":{"id":"2REwpHGWWg-_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217537,"user_tz":-180,"elapsed":60398,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"0ce1b798-4846-4035-afc6-542c846add04"},"source":["tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['do', \"n't\", 'stop', 'me']"]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"markdown","metadata":{"id":"Tckre90JWg_B"},"source":["А некоторые -- вообще не для текста на естественном языке:"]},{"cell_type":"code","metadata":{"id":"F1Ml3xtaWg_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217539,"user_tz":-180,"elapsed":60384,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"5257753a-90ef-45ea-e674-b0e313457364"},"source":["tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['(a (b c))', 'd', 'e', '(f)']"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"bM2kvAo0_b93"},"source":["**Правильный токенизатор подбирается исходя из требований задачи!**"]},{"cell_type":"markdown","metadata":{"id":"rhVrgkSaWg_K"},"source":["## Стоп-слова\n","\n","**Стоп-слова** - это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе. Для модели это просто шум. А шум нужно убирать. По аналогичной причине убирают и пунктуацию."]},{"cell_type":"code","metadata":{"id":"Ld-h6WKyWg_K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733217540,"user_tz":-180,"elapsed":60369,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"3e03085d-458e-4429-fe6e-f8ac7f38c33c"},"source":["# импортируем стоп-слова из библиотеки nltk\n","from nltk.corpus import stopwords\n","\n","# посмотрим на стоп-слова для русского языка\n","print(stopwords.words('russian'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yHg5Z93iAyee"},"source":["noise = stopwords.words('russian')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t3gweXaWWg_P"},"source":["Теперь нужно обучать нашу модель с учетом новых знаний про токенизацию и стоп-слова. \n","\n","Для этого мы можем собрать новый векторизатор, передав ему на вход:\n","* какие n-граммы нам нужны, параметр **ngram_range**;\n","* какой токенизатор мы используем, параметр **tokenizer**;\n","* какие у нас стоп-слова, параметр **stop_words**."]},{"cell_type":"code","metadata":{"id":"fbXrVeRRuAxx"},"source":["# инициализируем умный векторайзер \n","smart_vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=noise)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCM2Jy0448Mc"},"source":["# обучаем его и сразу применяем к x_train\n","smart_vectorized_x_train = smart_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTiC4oUX5T__","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733218900,"user_tz":-180,"elapsed":61667,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"9f0fbfc2-e3c7-4db9-88d3-23af81621495"},"source":["smart_vectorized_x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999, 44348)"]},"metadata":{"tags":[]},"execution_count":122}]},{"cell_type":"code","metadata":{"id":"7BztanE26o5Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733218902,"user_tz":-180,"elapsed":61654,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"d97420cb-99b8-45ae-ecce-b75175b1a2f6"},"source":["list(smart_vectorizer.vocabulary_.items())[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('пришёл', 31452),\n"," ('мал', 17955),\n"," ('материал', 18213),\n"," ('ожидался', 23391),\n"," ('немного', 20921),\n"," ('прозрачный', 31910),\n"," ('товар', 39502),\n"," ('пришел', 31385),\n"," ('менее', 18398),\n"," ('недели', 20604)]"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"7Nc6D-nwWg_P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733218905,"user_tz":-180,"elapsed":61643,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"e3d8de55-df11-4614-d428-fa5d5e2d3002"},"source":["# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(smart_vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"OQ-P91PV5KST"},"source":["# применяем обученный векторайзер к тестовым данным\n","smart_vectorized_x_test = smart_vectorizer.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QJ3elF85MDB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733220219,"user_tz":-180,"elapsed":62924,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"556c5887-58da-4835-94ec-fdfbbcc6f8c1"},"source":["# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(smart_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.58      0.65      0.61      9054\n","    negative       0.71      0.61      0.66      8966\n","    positive       0.82      0.84      0.83      8981\n","\n","    accuracy                           0.70     27001\n","   macro avg       0.70      0.70      0.70     27001\n","weighted avg       0.70      0.70      0.70     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DYWB1foQWg_T"},"source":["Получилось чуть хуже. \n","\n","Что ещё можно сделать?"]},{"cell_type":"markdown","metadata":{"id":"XsRf9T_SWg_U"},"source":["## Лемматизация\n","\n","**Лемматизация** – это сведение разных форм одного слова к начальной форме – **лемме**. Почему это хорошо?\n","* Во-первых, естественно рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n","* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n","\n","Для русского есть хороший лемматизатор pymorphy. \n","\n","Стемминг (англ. stemming — находить происхождение) — это процесс нахождения основы слова для заданного исходного слова. Основа слова не обязательно совпадает с морфологическим корнем слова. "]},{"cell_type":"markdown","metadata":{"id":"ylKZG2MwWg_f"},"source":["### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n","Это модуль на питоне, довольно быстрый и с кучей функций."]},{"cell_type":"code","metadata":{"id":"JcYWYq4BzOon","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733224281,"user_tz":-180,"elapsed":66971,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"03f60d55-1e3e-4548-9855-d8e91296c824"},"source":["# устанавливаем pymorphy2\n","!pip install pymorphy2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pymorphy2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n","\r\u001b[K     |██████                          | 10kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n","\u001b[?25hCollecting dawg-python>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n","Collecting pymorphy2-dicts-ru<3.0,>=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n","\u001b[K     |████████████████████████████████| 8.2MB 4.9MB/s \n","\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n","Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IqdT2pmRFn2F"},"source":["В pymorphy2 для морфологического анализа слов есть ```MorphAnalyzer()```:"]},{"cell_type":"code","metadata":{"id":"m4nRuUu2Wg_g"},"source":["from pymorphy2 import MorphAnalyzer\n","pymorphy2_analyzer = MorphAnalyzer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Egd6KdqzWg_h"},"source":["pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает:"]},{"cell_type":"code","metadata":{"id":"M6hdm1KBFx18"},"source":["sentence = 'Кто же победит на выборах в США: Трамп или Байден?'\n","sent = word_tokenize(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cr1C2beNF3vE"},"source":["Лемматизируем слово \"победит\" из предложения ```sentence``` с помощью метода ```parse()```:"]},{"cell_type":"code","metadata":{"id":"1Q3zNlPBWg_i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733224288,"user_tz":-180,"elapsed":66929,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"85cf5bcc-bf2d-4a9b-b71b-1e58cddf5f7d"},"source":["ana = pymorphy2_analyzer.parse(sent[2])\n","ana"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parse(word='победит', tag=OpencorporaTag('VERB,perf,tran sing,3per,futr,indc'), normal_form='победить', score=0.846153, methods_stack=((DictionaryAnalyzer(), 'победит', 2483, 9),)),\n"," Parse(word='победит', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='победит', score=0.076923, methods_stack=((DictionaryAnalyzer(), 'победит', 34, 0),)),\n"," Parse(word='победит', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='победит', score=0.076923, methods_stack=((DictionaryAnalyzer(), 'победит', 34, 3),))]"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"markdown","metadata":{"id":"m2O2BL4_GJzq"},"source":["Выведем его нормальную форму:"]},{"cell_type":"code","metadata":{"id":"7-zp0KZLWg_p","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1604733224290,"user_tz":-180,"elapsed":66915,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"1291a6f2-bcb3-4655-8ffd-50c396922372"},"source":["ana[0].normal_form"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'победить'"]},"metadata":{"tags":[]},"execution_count":131}]},{"cell_type":"markdown","metadata":{"id":"qUzhGLTxLIr9"},"source":["Нормализация предложения \"вижу три села\" может дать \"видеть тереть сесть\""]},{"cell_type":"code","metadata":{"id":"ldFCYxXuLL4p"},"source":["sent2 = word_tokenize('вижу три села')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKRiNng-LfoP","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1604733224294,"user_tz":-180,"elapsed":66889,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"95fe3b5e-408f-437a-fa2d-db50d16d63d6"},"source":["ana2 = pymorphy2_analyzer.parse(sent2[2])\n","ana2[0].normal_form"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'село'"]},"metadata":{"tags":[]},"execution_count":133}]},{"cell_type":"markdown","metadata":{"id":"VlWxW3e9Wg-m"},"source":["## TF-IDF векторизация"]},{"cell_type":"markdown","metadata":{"id":"u7hCxZRtWg-m"},"source":["`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений выдает **tf-idf** каждого слова.\n","\n","Как считается tf-idf:\n","\n","**TF (term frequency)** – относительная частотность слова в документе:\n","$$ TF(t,d) = \\frac{n_{t}}{\\sum_k n_{k}} $$\n","\n","**IDF (inverse document frequency)** – обратная частота документов, в которых есть это слово:\n","$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n","\n","Перемножаем их:\n","$$TFIDF(t, d, D) = TF(t,d) \\times IDF(i, D)$$\n","\n","Cмысл: если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n","количестве документов, у него высокий TF-IDF."]},{"cell_type":"code","metadata":{"id":"Fv7DfTkJWg-n"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"02f_zZm14PHM"},"source":["Действуем аналогично, как с ```CountVectorizer()```:"]},{"cell_type":"code","metadata":{"id":"JjF9m3EOQTBK"},"source":["# инициализируем векторизатор, в качестве переменных используем униграммы\n","tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrTdCw_TDE9o"},"source":["# обучаем его и сразу применяем к x_train\n","tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPacf_DKDP7M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733225871,"user_tz":-180,"elapsed":68407,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"ac946841-63f3-4832-ef6d-7137e8de4730"},"source":["# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(tfidf_vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"ljAO8NIPDSnK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733227185,"user_tz":-180,"elapsed":69703,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"4149b5f1-c69b-4060-969b-46e976730bda"},"source":["# применяем обученный векторизатор к тестовым данным\n","tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n","\n","# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(tfidf_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.67      0.63      9054\n","    negative       0.72      0.63      0.67      8966\n","    positive       0.84      0.84      0.84      8981\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.72      0.71      0.71     27001\n","weighted avg       0.72      0.71      0.71     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9hedBdcYWhAH"},"source":["Иногда пунктуация бывает и не шумом - главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию? На примере с твитами хорошо было бы видно, что пунктуация работает хорошо ))"]},{"cell_type":"code","metadata":{"id":"XhZMwsY5WhAI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733256222,"user_tz":-180,"elapsed":98724,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"2112e2cb-232e-4a9a-8fbe-ea32b1479a64"},"source":["# инициализируем умный векторайзер stop-words НЕ ИСПОЛЬЗУЕМ!\n","alternative_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n","                                               tokenizer=word_tokenize)\n","\n","# обучаем его и сразу применяем к x_train\n","alternative_tfidf_vectorized_x_train = alternative_tfidf_vectorizer.fit_transform(x_train)\n","\n","# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(alternative_tfidf_vectorized_x_train, y_train)\n","\n","# применяем обученный векторайзер к тестовым данным\n","alternative_tfidf_vectorized_x_test = alternative_tfidf_vectorizer.transform(x_test)\n","\n","# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(alternative_tfidf_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.67      0.63      9054\n","    negative       0.72      0.64      0.68      8966\n","    positive       0.85      0.84      0.84      8981\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.72      0.71      0.72     27001\n","weighted avg       0.72      0.71      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FEQbCtidWhAP"},"source":["Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"]},{"cell_type":"code","metadata":{"id":"rhUG9qWuWhAQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733256589,"user_tz":-180,"elapsed":99056,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"98ed552c-afb1-43d0-cdad-2676c7b3e1c5"},"source":["cool_token = 'плохо'\n","pred = ['positive' if cool_token in review else 'negative' for review in x_test]\n","print(classification_report(pred, y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.00      0.00      0.00         0\n","    negative       0.94      0.33      0.49     25808\n","    positive       0.02      0.14      0.03      1193\n","\n","    accuracy                           0.32     27001\n","   macro avg       0.32      0.16      0.17     27001\n","weighted avg       0.90      0.32      0.47     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JrqW55jgWhAR"},"source":["## Символьные n-граммы\n","\n","В некоторых задачах в качестве признаков могут быть использщованы, n-граммы символов. Для этого необходимо установить в ```CountVectorizer()``` параметр ```analyzer = 'char'```, то есть анализировать символы."]},{"cell_type":"code","metadata":{"id":"o4lNhEmyWhAU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604733306851,"user_tz":-180,"elapsed":149301,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"37670763-b615-439d-be3f-31cf89cd96a0"},"source":["# инициализируем векторайзер для символов\n","char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 6))\n","\n","# обучаем его и сразу применяем к x_train\n","char_vectorized_x_train = char_vectorizer.fit_transform(x_train)\n","\n","# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(char_vectorized_x_train, y_train)\n","\n","# применяем обученный векторайзер к тестовым данным\n","char_vectorized_x_test = char_vectorizer.transform(x_test)\n","\n","# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(char_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.71      0.64      9054\n","    negative       0.73      0.62      0.67      8966\n","    positive       0.87      0.83      0.85      8981\n","\n","    accuracy                           0.72     27001\n","   macro avg       0.73      0.72      0.72     27001\n","weighted avg       0.73      0.72      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pLMMicsFWhAY"},"source":["Cимвольные n-граммы используются, например, для задачи определения языка. Ещё одна замечательная особенность признаков-символов - для них не нужна токенизация и лемматизация, можно использовать такой подход для языков, у которых нет готовых анализаторов."]}]}